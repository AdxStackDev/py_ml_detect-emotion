# Emotion Detection using CNN (PyTorch) - Production Ready

A comprehensive PyTorch-based Convolutional Neural Network for detecting emotions from grayscale facial images. This production-ready version includes:
- âœ¨ **Web Interface** - Beautiful drag & drop UI for batch processing
- ğŸš€ **ONNX Export** - Deploy to web, mobile, cloud, and edge devices
- ğŸ“Š **Advanced Training** - Validation splits, class balancing, early stopping
- ğŸ“ˆ **Comprehensive Metrics** - Accuracy, precision, recall, F1-score, confusion matrix
- ğŸ¨ **Visualization Tools** - Training curves, sample predictions, detailed analysis

---

## ğŸ“‚ Project Structure

```
detectEmotions/
â”œâ”€â”€ emotion_dataset/           # Training dataset
â”‚   â”œâ”€â”€ angry/                # 515 images (22.6%)
â”‚   â”œâ”€â”€ happy/                # 1,006 images (44.2%)
â”‚   â””â”€â”€ sad/                  # 757 images (33.2%)
â”‚
â”œâ”€â”€ ğŸ¯ Training & Inference
â”œâ”€â”€ train_improved.py         # Enhanced training script
â”œâ”€â”€ inference_improved.py     # Enhanced inference script
â”œâ”€â”€ analyze_model.py          # Model analysis utility
â”œâ”€â”€ emotions.py               # Original training script
â”œâ”€â”€ detect_emotion.py         # Original inference script
â”‚
â”œâ”€â”€ ğŸŒ Web Interface (NEW!)
â”œâ”€â”€ app.py                    # Flask web server
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html           # Main upload interface
â”‚   â””â”€â”€ details.html         # Detailed analysis page
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css            # Premium dark theme styling
â”‚   â”œâ”€â”€ script.js            # Main page logic
â”‚   â””â”€â”€ details.js           # Details page logic
â”‚
â”œâ”€â”€ ğŸš€ ONNX Deployment (NEW!)
â”œâ”€â”€ export_onnx_simple.py     # Export PyTorch to ONNX
â”œâ”€â”€ test_onnx.py              # Test ONNX model
â”œâ”€â”€ emotion_model.onnx        # Exported ONNX model
â”‚
â”œâ”€â”€ ğŸ’¾ Models
â”œâ”€â”€ sad_happy_angry.pth       # Trained PyTorch model
â”œâ”€â”€ emotion_model.onnx        # ONNX format (for deployment)
â”‚
â”œâ”€â”€ ğŸ“Š Results & Analysis
â”œâ”€â”€ training_results/         # Training outputs
â”œâ”€â”€ analysis_results/         # Analysis outputs
â”œâ”€â”€ uploads/                  # Web UI uploaded images
â”œâ”€â”€ results.json              # Web UI processing history
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ WEB_INTERFACE.md          # Web UI documentation
â”œâ”€â”€ ONNX_DEPLOYMENT.md        # ONNX deployment guide
â”œâ”€â”€ QUICKSTART_WEB.md         # Web UI quick start
â””â”€â”€ report.html              # Analysis report
```

---

## ğŸ¯ Detected Emotion Classes

- **angry** ğŸ˜ 
- **happy** ğŸ˜Š
- **sad** ğŸ˜¢

---

## ğŸ› ï¸ Requirements

Install all dependencies:

```bash
pip install -r requirements.txt
```

**Dependencies:**
- Python 3.8+
- PyTorch >= 2.0.0
- torchvision >= 0.15.0
- Pillow >= 9.0.0
- matplotlib >= 3.5.0
- numpy >= 1.21.0
- scikit-learn >= 1.0.0
- seaborn >= 0.12.0
- Flask >= 2.3.0 (for web interface)
- onnx >= 1.14.0 (for ONNX export)
- onnxruntime >= 1.15.0 (for ONNX inference)

---

## ğŸš€ Quick Start

### 1. Train the Model (Improved Version)

```bash
python train_improved.py
```

**Features:**
- âœ… 80/20 train/validation split
- âœ… Class-weighted loss for imbalance handling
- âœ… Early stopping (patience=10)
- âœ… Learning rate scheduling
- âœ… Comprehensive metrics (accuracy, precision, recall, F1)
- âœ… Confusion matrix and learning curves
- âœ… Model checkpointing (saves best model)
- âœ… Data augmentation (flip, rotation, brightness)
- âœ… Batch normalization and dropout

**Output:**
- `emotion_model.pth` - Final model weights
- `best_emotion_model.pth` - Best checkpoint with metadata
- `training_results/` - Visualizations and metrics

### 2. Run Inference (Improved Version)

**Single image:**
```bash
python inference_improved.py --image path/to/image.png
```

**Multiple images:**
```bash
python inference_improved.py --images img1.png img2.png img3.png
```

**Show probability distribution:**
```bash
python inference_improved.py --image test.png --show-probs
```

**Custom model and classes:**
```bash
python inference_improved.py --model custom_model.pth --classes angry happy sad neutral
```

**Default (uses test images):**
```bash
python inference_improved.py
```

### 3. Analyze the Model

```bash
python analyze_model.py
```

**Analysis includes:**
- Dataset distribution and class imbalance
- Model architecture and parameter count
- Model file size
- Inference speed (FPS)
- Sample predictions visualization

---

## ğŸŒ Web Interface (NEW!)

A beautiful, production-ready web application with drag & drop batch processing.

### Features
- âœ¨ **Premium Dark Theme** - Modern UI with vibrant gradients
- ğŸ“¤ **Drag & Drop Upload** - Easy batch image upload
- ğŸ”„ **Real-time Processing** - Live progress indicators
- ğŸ“Š **Grid Results** - Beautiful result cards with emotion badges
- ğŸ” **Detailed Analysis** - Full metadata and probability distribution
- ğŸ’¾ **Result History** - Persistent storage in JSON

### Quick Start

1. **Start the web server:**
```bash
python app.py
```

2. **Open your browser:**
```
http://127.0.0.1:5001
```

3. **Upload images:**
   - Drag & drop images onto the upload zone
   - Or click "Browse Files" to select images
   - Process single or multiple images at once

4. **View results:**
   - See emotion predictions in a grid layout
   - Click "View Details" for comprehensive analysis
   - Review probability distribution and metadata

### Web Interface Features

- **Batch Processing** - Upload and analyze multiple images simultaneously
- **Color-Coded Emotions** - Instant visual feedback (Green=Happy, Blue=Sad, Red=Angry)
- **Confidence Scores** - See prediction confidence for each image
- **Detailed Pages** - Full analysis with image metadata and processing info
- **Responsive Design** - Works on desktop, tablet, and mobile
- **Fast Performance** - <100ms processing per image

### API Endpoints

The web interface also provides REST API endpoints:

```bash
# Upload and process images
POST /api/upload
Content-Type: multipart/form-data

# Get specific result
GET /api/result/{result_id}

# Get all processing history
GET /api/history
```

**Documentation:** See `WEB_INTERFACE.md` and `QUICKSTART_WEB.md` for detailed guides.

---

## ğŸš€ ONNX Deployment (NEW!)

Export your PyTorch model to ONNX format for cross-platform deployment!

### Why ONNX?
- âœ… **Faster Inference** - Optimized runtime performance
- âœ… **Cross-Platform** - Deploy to web, mobile, cloud, edge devices
- âœ… **Framework Agnostic** - Use with TensorFlow, PyTorch, etc.
- âœ… **Production Ready** - Industry-standard format
- âœ… **Smaller Size** - More compact than PyTorch models

### Quick Start

1. **Install ONNX dependencies:**
```bash
pip install onnx onnxruntime
```

2. **Export model to ONNX:**
```bash
python export_onnx_simple.py
```

**Output:**
```
============================================================
PYTORCH TO ONNX EXPORT
============================================================

[1/4] Loading PyTorch model...
  OK - Model loaded

[2/4] Creating dummy input...
  OK - Input shape: (1, 1, 48, 48)

[3/4] Exporting to ONNX...
  OK - Exported to emotion_model.onnx

[4/4] Verifying export...
  OK - File created: 0.01 MB

============================================================
EXPORT COMPLETE!
============================================================
```

3. **Test ONNX model:**
```bash
python test_onnx.py
```

**Output:**
```
============================================================
ONNX MODEL INFERENCE TEST
============================================================

[1/4] Loading ONNX model...
  OK - Model loaded: emotion_model.onnx

[2/4] Model information...
  Input name: input
  Input shape: [1, 1, 48, 48]
  Output name: output
  Output shape: [1, 3]

[3/4] Processing image: boy.png...
  OK - Image processed, shape: (1, 1, 48, 48)

[4/4] Running inference...
  OK - Inference complete

============================================================
RESULTS
============================================================

Image: boy.png
Predicted Emotion: ANGRY
Confidence: 99.82%

Probability Distribution:
  angry   : 99.82% #################################################
  happy   :  0.01%
  sad     :  0.17%

============================================================
TEST COMPLETE!
============================================================
```

### Deployment Options

#### 1. Web Deployment (ONNX.js)
```javascript
const onnx = require('onnxjs');
const session = new onnx.InferenceSession();
await session.loadModel('emotion_model.onnx');
```

#### 2. Mobile Deployment
- **iOS**: ONNX Runtime for iOS
- **Android**: ONNX Runtime for Android

#### 3. Cloud Deployment
- **AWS Lambda**: Serverless inference
- **Azure Functions**: Cloud-based processing
- **Google Cloud**: Cloud Run deployment

#### 4. Edge Devices
- **Raspberry Pi**: Lightweight inference
- **NVIDIA Jetson**: GPU-accelerated processing
- **Intel NUC**: Desktop edge computing

### ONNX Model Specifications

**Input:**
- Name: `input`
- Shape: `[batch_size, 1, 48, 48]`
- Type: `float32`
- Range: `-1.0 to 1.0` (normalized)

**Output:**
- Name: `output`
- Shape: `[batch_size, 3]`
- Type: `float32`
- Classes: `['angry', 'happy', 'sad']`

### Using ONNX in Python

```python
import onnxruntime as ort
import numpy as np
from PIL import Image
from torchvision import transforms

# Load ONNX model
session = ort.InferenceSession('emotion_model.onnx')

# Prepare image
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((48, 48)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

image = Image.open('test.png')
img_tensor = transform(image).unsqueeze(0).numpy()

# Run inference
outputs = session.run(None, {'input': img_tensor})
predictions = outputs[0]

# Get emotion
emotions = ['angry', 'happy', 'sad']
emotion = emotions[np.argmax(predictions)]
print(f"Predicted Emotion: {emotion}")
```

**Documentation:** See `ONNX_DEPLOYMENT.md` for comprehensive deployment guide.

---

## ğŸ“Š Model Architecture

### ImprovedEmotionCNN

```
Input: 1Ã—48Ã—48 grayscale image
  â†“
Conv2D (1â†’32) + BatchNorm + ReLU + MaxPool â†’ [32, 24, 24]
  â†“
Conv2D (32â†’64) + BatchNorm + ReLU + MaxPool â†’ [64, 12, 12]
  â†“
Conv2D (64â†’128) + BatchNorm + ReLU + MaxPool â†’ [128, 6, 6]
  â†“
Flatten â†’ 4,608 features
  â†“
FC (4,608â†’256) + ReLU + Dropout(0.5)
  â†“
FC (256â†’128) + ReLU + Dropout(0.5)
  â†“
FC (128â†’3) â†’ Output logits
```

**Parameters:** ~1.2M  
**Model Size:** ~5 MB  
**Expected Accuracy:** 75-85% (with improvements)

---

## ğŸ”§ What's Improved?

### Critical Fixes

1. **âœ… Fixed filename mismatch bug** in `emotions.py`
   - Was saving as `sad_happy_angry1.pth` but loading `sad_happy_angry.pth`

2. **âœ… Added train/validation split (80/20)**
   - Prevents overfitting
   - Enables proper evaluation

3. **âœ… Class-weighted loss**
   - Handles class imbalance (happy: 44%, sad: 33%, angry: 23%)
   - Prevents bias toward majority class

4. **âœ… Comprehensive metrics tracking**
   - Accuracy, precision, recall, F1-score
   - Confusion matrix
   - Per-class accuracy

### Major Enhancements

5. **âœ… Early stopping**
   - Stops training when validation loss stops improving
   - Saves best model checkpoint

6. **âœ… Learning rate scheduling**
   - Reduces LR when validation loss plateaus
   - Improves convergence

7. **âœ… Improved architecture**
   - Added 3rd convolutional layer
   - Batch normalization for stable training
   - Dropout for regularization

8. **âœ… Data augmentation**
   - Random horizontal flip
   - Random rotation (Â±10Â°)
   - Brightness jittering

9. **âœ… Visualization**
   - Training/validation loss curves
   - Accuracy curves
   - Confusion matrix heatmap
   - Per-class accuracy bar chart

10. **âœ… Error handling**
    - Try/except blocks for file I/O
    - Graceful error messages
    - Input validation

11. **âœ… Command-line interface**
    - Flexible inference options
    - Probability display
    - Custom model/class support

12. **âœ… Documentation**
    - requirements.txt
    - Comprehensive README
    - Inline code comments

---

## ğŸ“ˆ Expected Performance

### Original Model
- Accuracy: 60-75%
- Issues: Class imbalance, no validation, overfitting

### Improved Model
- Accuracy: 75-85%
- Balanced predictions across classes
- Better generalization
- Robust to variations

---

## ğŸ“ Usage Examples

### Training with Custom Settings

Edit `train_improved.py` to customize:
- `EPOCHS` - Maximum training epochs (default: 50)
- `batch_size` - Batch size (default: 32)
- `patience` - Early stopping patience (default: 10)
- `dropout_rate` - Dropout probability (default: 0.5)
- Learning rate, optimizer, etc.

### Inference Examples

```bash
# Basic inference
python inference_improved.py --image crying.png

# Show probabilities
python inference_improved.py --image boy.png --show-probs

# Batch inference
python inference_improved.py --images *.png

# Use original model
python inference_improved.py --model sad_happy_angry.pth --image test.png
```

---

## ğŸš€ Potential Use Cases

- **Mental health monitoring** - Track emotional trends over time
- **Customer service** - Analyze sentiment from video calls
- **Education** - Monitor student engagement in online classes
- **Gaming** - Adaptive difficulty based on player emotions
- **Marketing** - A/B test content via emotional reactions
- **Accessibility** - Emotion-aware assistive technologies

---

## ğŸ“Œ Future Improvements

### High Priority
- [ ] Collect more data for minority classes (angry)
- [ ] Add more emotion classes (surprise, fear, disgust, neutral)
- [ ] Implement test-time augmentation
- [ ] Cross-validation for robust evaluation

### Medium Priority
- [ ] Transfer learning with pre-trained models (ResNet, EfficientNet)
- [ ] Ensemble methods for better accuracy
- [ ] Real-time webcam inference
- [ ] Web interface (Flask/Streamlit)

### Completed âœ…
- [x] Export to ONNX for deployment
- [x] Web interface (Flask)
- [x] Batch processing support
- [x] Detailed analysis pages

### Low Priority
- [ ] Mobile optimization (TensorFlow Lite)
- [ ] Multi-face detection and tracking
- [ ] Temporal smoothing for video
- [ ] Real-time webcam inference

---

## ï¿½ Complete Feature List

### âœ… Core Features
- [x] CNN-based emotion detection (3 classes: angry, happy, sad)
- [x] PyTorch implementation with GPU support
- [x] Train/validation split (80/20)
- [x] Class-weighted loss for imbalance handling
- [x] Early stopping and learning rate scheduling
- [x] Data augmentation (flip, rotation, brightness)
- [x] Comprehensive metrics (accuracy, precision, recall, F1)

### âœ… Web Interface
- [x] Beautiful dark theme with gradients and animations
- [x] Drag & drop batch image upload
- [x] Real-time processing with progress indicators
- [x] Grid-based results display
- [x] Detailed analysis pages with metadata
- [x] REST API endpoints
- [x] Result persistence in JSON

### âœ… ONNX Deployment
- [x] Export PyTorch model to ONNX format
- [x] Cross-platform deployment support
- [x] Optimized inference performance
- [x] Web, mobile, cloud, and edge deployment options
- [x] Comprehensive deployment documentation

### âœ… Analysis & Visualization
- [x] Training/validation curves
- [x] Confusion matrix heatmap
- [x] Per-class accuracy charts
- [x] Sample predictions visualization
- [x] Model architecture analysis
- [x] Dataset distribution analysis

---

## ğŸš€ All-in-One Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Train the model (optional - model already included)
python train_improved.py

# 3. Test inference
python inference_improved.py --image boy.png --show-probs

# 4. Analyze the model
python analyze_model.py

# 5. Start web interface
python app.py
# Open: http://127.0.0.1:5001

# 6. Export to ONNX
python export_onnx_simple.py

# 7. Test ONNX model
python test_onnx.py
```

---

## ğŸ“– Documentation

- **README.md** (this file) - Main documentation
- **WEB_INTERFACE.md** - Web UI technical documentation
- **QUICKSTART_WEB.md** - Web UI user guide
- **ONNX_DEPLOYMENT.md** - ONNX deployment guide
- **IMPROVEMENTS.md** - Detailed improvement changelog
- **SUMMARY.md** - Project analysis and recommendations
- **report.html** - Interactive analysis report

---

## ğŸ¯ Use Cases

This emotion detection system can be used for:

- **Mental Health Monitoring** - Track emotional trends over time
- **Customer Service** - Analyze sentiment from video calls
- **Education** - Monitor student engagement in online classes
- **Gaming** - Adaptive difficulty based on player emotions
- **Marketing** - A/B test content via emotional reactions
- **Accessibility** - Emotion-aware assistive technologies
- **Security** - Emotion-based authentication
- **Healthcare** - Patient emotional state monitoring

---

## ï¿½ğŸ“œ License

Free to use, modify, and share for educational purposes. âœ¨

---

## ğŸ™ Acknowledgments

- Dataset augmented with brightness and rotation variants
- Built with PyTorch and torchvision
- Visualization using matplotlib and seaborn
- Web interface powered by Flask
- ONNX export for cross-platform deployment

---

## ğŸ“ Support

For questions, issues, or contributions:
- Check the documentation files
- Review the `report.html` for detailed analysis
- See `QUICKSTART_WEB.md` for web interface help
- See `ONNX_DEPLOYMENT.md` for deployment guidance

---

**ğŸ‰ Happy Learning & Building!**

This is a production-ready emotion detection system with:
- âœ… Advanced training pipeline
- âœ… Beautiful web interface
- âœ… Cross-platform deployment
- âœ… Comprehensive documentation

**Ready to deploy anywhere!** ğŸš€
