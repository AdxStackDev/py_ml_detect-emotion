# Quick Start Guide - Emotion Detection Project

This guide will get you up and running with the improved emotion detection system in 5 minutes.

---

## ğŸ“¦ Step 1: Install Dependencies (30 seconds)

```bash
pip install -r requirements.txt
```

This installs:
- PyTorch (deep learning framework)
- torchvision (image processing)
- matplotlib, seaborn (visualization)
- scikit-learn (metrics)
- Pillow (image loading)

---

## ğŸ“ Step 2: Train the Model (5-10 minutes)

### Option A: Improved Version (Recommended)

```bash
python train_improved.py
```

**What happens:**
- Loads 2,278 images from `emotion_dataset/`
- Splits into 80% train (1,822) and 20% validation (456)
- Trains enhanced CNN with batch normalization and dropout
- Uses class-weighted loss to handle imbalance
- Implements early stopping (stops when no improvement)
- Saves best model as `emotion_model.pth`
- Generates visualizations in `training_results/`

**Expected time:** 5-10 minutes on CPU, 2-3 minutes on GPU

**Output files:**
- `emotion_model.pth` - Final model
- `best_emotion_model.pth` - Best checkpoint
- `training_results/training_history.png` - Learning curves
- `training_results/confusion_matrix.png` - Confusion matrix
- `training_results/per_class_accuracy.png` - Per-class metrics
- `training_results/model_info.txt` - Training summary

### Option B: Original Version (Fixed)

```bash
python emotions.py
```

**What happens:**
- Trains original 2-layer CNN
- Fixed 10 epochs
- No validation split
- Saves as `sad_happy_angry.pth`

**Expected time:** 2-3 minutes

---

## ğŸ”® Step 3: Run Inference (Instant)

### Basic Usage

```bash
# Use default test images
python inference_improved.py
```

### Advanced Usage

```bash
# Single image
python inference_improved.py --image crying.png

# Multiple images
python inference_improved.py --images boy.png person.png crying.png

# Show probability distribution
python inference_improved.py --image boy.png --show-probs
```

**Example output:**
```
Image: boy.png
  Predicted Emotion: HAPPY
  Probability Distribution:
    angry   :  5.23% â–ˆâ–ˆ
    happy   : 87.45% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    sad     :  7.32% â–ˆâ–ˆâ–ˆ
```

---

## ğŸ“Š Step 4: Analyze the Model (30 seconds)

```bash
python analyze_model.py
```

**What you get:**
- Dataset statistics and class distribution
- Model architecture details
- Parameter count and model size
- Inference speed (FPS)
- Sample predictions visualization

**Output:**
```
DATASET ANALYSIS
Total samples: 2,278
Classes: ['angry', 'happy', 'sad']

Class Distribution:
  angry   :  515 (22.6%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  happy   : 1006 (44.2%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  sad     :  757 (33.2%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

MODEL ARCHITECTURE ANALYSIS
Total parameters: 1,234,567
Model size: 4.98 MB

Inference Speed:
  Average time: 12.34 ms
  FPS: 81.0
```

---

## ğŸ¯ Step 5: Review Results

### Check Training Results

```bash
# Open visualizations
start training_results/training_history.png
start training_results/confusion_matrix.png
start training_results/per_class_accuracy.png

# Read training summary
type training_results/model_info.txt
```

### Check Analysis Results

```bash
start analysis_results/sample_predictions.png
```

---

## ğŸš€ Common Workflows

### Workflow 1: Train and Test

```bash
# 1. Train
python train_improved.py

# 2. Test on your images
python inference_improved.py --images my_photo1.jpg my_photo2.jpg --show-probs

# 3. Analyze
python analyze_model.py
```

### Workflow 2: Quick Experiment

```bash
# Use original script for quick experiments
python emotions.py
python detect_emotion.py
```

### Workflow 3: Production Deployment

```bash
# 1. Train with best settings
python train_improved.py

# 2. Test thoroughly
python inference_improved.py --images test_set/*.png

# 3. Verify performance
python analyze_model.py

# 4. Deploy emotion_model.pth
```

---

## ğŸ“ Project Structure After Setup

```
detectEmotions/
â”œâ”€â”€ emotion_dataset/          # Your training data
â”œâ”€â”€ train_improved.py         # Enhanced training
â”œâ”€â”€ inference_improved.py     # Enhanced inference
â”œâ”€â”€ analyze_model.py          # Analysis tool
â”œâ”€â”€ emotion_model.pth         # âœ¨ Trained model
â”œâ”€â”€ best_emotion_model.pth    # âœ¨ Best checkpoint
â”œâ”€â”€ training_results/         # âœ¨ Training outputs
â”‚   â”œâ”€â”€ training_history.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ per_class_accuracy.png
â”‚   â””â”€â”€ model_info.txt
â””â”€â”€ analysis_results/         # âœ¨ Analysis outputs
    â””â”€â”€ sample_predictions.png
```

---

## â“ Troubleshooting

### Issue: "No module named 'torch'"

**Solution:**
```bash
pip install -r requirements.txt
```

### Issue: "Dataset directory not found"

**Solution:**
Make sure `emotion_dataset/` exists with subfolders:
```
emotion_dataset/
â”œâ”€â”€ angry/
â”œâ”€â”€ happy/
â””â”€â”€ sad/
```

### Issue: "Model file not found"

**Solution:**
Train the model first:
```bash
python train_improved.py
```

### Issue: Training is slow

**Solutions:**
- Use GPU if available (automatically detected)
- Reduce batch size in `train_improved.py`
- Reduce max epochs (default: 50)

### Issue: Low accuracy

**Solutions:**
- Collect more training data
- Balance class distribution
- Increase training epochs
- Try different hyperparameters

---

## ğŸ“ Next Steps

1. **Read the full documentation:** `README.md`
2. **Review improvements:** `IMPROVEMENTS.md`
3. **Check the analysis report:** `report.html`
4. **Experiment with hyperparameters**
5. **Add your own images**
6. **Extend to more emotion classes**

---

## ğŸ“ Need Help?

- Check `README.md` for detailed documentation
- Review `IMPROVEMENTS.md` for technical details
- Open `report.html` for visual analysis
- Check code comments for inline documentation

---

**Happy Emotion Detecting! ğŸ˜Š**
